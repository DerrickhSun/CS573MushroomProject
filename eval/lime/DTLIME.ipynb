{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac40d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950a87a3-36ae-4512-b363-899f7cc625a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "%run models/tree_impl.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd627557-49c4-41a0-ae8f-608576064eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Structure:\n",
      "Feature: odor\n",
      " -> If odor == 0:\n",
      "    Leaf: 0\n",
      " -> If odor == 1:\n",
      "    Leaf: 1\n",
      " -> If odor == 2:\n",
      "    Leaf: 1\n",
      " -> If odor == 3:\n",
      "    Leaf: 0\n",
      " -> If odor == 4:\n",
      "    Leaf: 1\n",
      " -> If odor == 5:\n",
      "    Feature: spore-print-color\n",
      "     -> If spore-print-color == 0:\n",
      "        Leaf: 0\n",
      "     -> If spore-print-color == 1:\n",
      "        Leaf: 0\n",
      "     -> If spore-print-color == 2:\n",
      "        Leaf: 0\n",
      "     -> If spore-print-color == 3:\n",
      "        Leaf: 0\n",
      "     -> If spore-print-color == 4:\n",
      "        Leaf: 0\n",
      "     -> If spore-print-color == 5:\n",
      "        Leaf: 1\n",
      "     -> If spore-print-color == 7:\n",
      "        Feature: habitat\n",
      "         -> If habitat == 0:\n",
      "            Feature: gill-size\n",
      "             -> If gill-size == 0:\n",
      "                Leaf: 0\n",
      "             -> If gill-size == 1:\n",
      "                Leaf: 1\n",
      "         -> If habitat == 1:\n",
      "            Leaf: 0\n",
      "         -> If habitat == 2:\n",
      "            Feature: cap-color\n",
      "             -> If cap-color == 1:\n",
      "                Leaf: 0\n",
      "             -> If cap-color == 4:\n",
      "                Leaf: 0\n",
      "             -> If cap-color == 8:\n",
      "                Leaf: 1\n",
      "             -> If cap-color == 9:\n",
      "                Leaf: 1\n",
      "         -> If habitat == 4:\n",
      "            Leaf: 0\n",
      "         -> If habitat == 6:\n",
      "            Leaf: 0\n",
      "     -> If spore-print-color == 8:\n",
      "        Leaf: 0\n",
      " -> If odor == 6:\n",
      "    Leaf: 1\n",
      " -> If odor == 7:\n",
      "    Leaf: 1\n",
      " -> If odor == 8:\n",
      "    Leaf: 1\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Do your reproducible split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42,     stratify=y\n",
    "\n",
    ")\n",
    "\n",
    "# 2) Instantiate your custom tree (no args needed)\n",
    "from models.tree_impl import DecisionTreeClassifierCustom, print_tree\n",
    "dt = DecisionTreeClassifierCustom()\n",
    "\n",
    "# 3) Fit on the training slice\n",
    "dt.fit(X_train, y_train, feature_names)\n",
    "print(\"Decision Tree Structure:\")\n",
    "print_tree(dt.tree, dt.original_feature_names)\n",
    "\n",
    "# 4) Evaluate on test\n",
    "print(\"Test accuracy:\", (dt.predict(X_test) == y_test).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4395d02-e7e7-4cd1-943c-060091630594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 1: One‑Hot Encode Train/Test Splits for Manhattan distance\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1) Reload raw data (strings) so we can one‑hot encode\n",
    "df_raw = pd.read_csv(\"data/mushroom_dataset.csv\")\n",
    "\n",
    "# 2) Create the same train/test split (stratified) on labels\n",
    "#    Using the y you already have from tree_impl, ensure it's the same order:\n",
    "X_all = df_raw.drop(columns=\"class\")\n",
    "y_all = df_raw[\"class\"]\n",
    "le = LabelEncoder().fit(df_raw[\"class\"])  # fits on all classes once\n",
    "y_all = le.transform(y_all)\n",
    "X_tr_raw, X_te_raw, y_train, y_test = train_test_split(\n",
    "    X_all, y_all,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y_all\n",
    ")\n",
    "\n",
    "# 3) One‑hot encode each split so distances are 0/1\n",
    "X_tr_oh = pd.get_dummies(X_tr_raw, columns=X_tr_raw.columns, drop_first=False)\n",
    "X_te_oh = pd.get_dummies(X_te_raw, columns=X_te_raw.columns, drop_first=False)\n",
    "\n",
    "# 4) Align columns (in case some rare category only appears in test)\n",
    "all_cols = sorted(set(X_tr_oh.columns).union(X_te_oh.columns))\n",
    "X_tr_oh = X_tr_oh.reindex(columns=all_cols, fill_value=0)\n",
    "X_te_oh = X_te_oh.reindex(columns=all_cols, fill_value=0)\n",
    "\n",
    "# 5) Grab numpy arrays & feature names\n",
    "X_train_oh = X_tr_oh.values\n",
    "X_test_oh  = X_te_oh.values\n",
    "feature_names_oh = all_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2471df6-4ba7-484e-b399-2a5c98619e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.tree_impl import label_encoders, feature_names\n",
    "import numpy as np\n",
    "# Build a map from each original feature to its one‑hot column indices and category names:\n",
    "oh_indices = {}\n",
    "for col in feature_names:\n",
    "    # one‑hot columns are named \"col_category\"\n",
    "    matches = [i for i, nm in enumerate(feature_names_oh) if nm.startswith(f\"{col}_\")]\n",
    "    # also grab the category string for each column:\n",
    "    cats = [nm.split(\"_\", 1)[1] for i, nm in enumerate(feature_names_oh) if nm.startswith(f\"{col}_\")]\n",
    "    oh_indices[col] = list(zip(matches, cats))\n",
    "\n",
    "def decode_one_hot_row(row_oh: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Turn a single one‑hot row into the integer‑encoded vector your tree expects.\"\"\"\n",
    "    decoded = []\n",
    "    for col in feature_names:\n",
    "        idxs_cats = oh_indices[col]\n",
    "        # find which dummy is '1'\n",
    "        for idx, cat in idxs_cats:\n",
    "            if row_oh[idx] == 1:\n",
    "                # encode that category back into the integer\n",
    "                decoded.append(label_encoders[col].transform([cat])[0])\n",
    "                break\n",
    "        else:\n",
    "            # if none ==1, maybe all zeros? default to most common\n",
    "            decoded.append(label_encoders[col].transform([idxs_cats[0][1]])[0])\n",
    "    return np.array(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09f7950f-8c45-4882-8473-e6e51a6d5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 3 (revised): DT + k‑medoids + LIME SUMMARY exactly like NBC\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# 1) cluster on the **test** split, not train\n",
    "kmed    = KMedoids(n_clusters=40, metric=\"manhattan\", random_state=0)\n",
    "kmed.fit(X_test_oh)                             # <— test here\n",
    "rep_idx = kmed.medoid_indices_\n",
    "\n",
    "# 2) background stays the **training** one‑hot\n",
    "bg_data = X_train_oh\n",
    "\n",
    "# 3) same wrapper\n",
    "def dt_predict_proba(arr_oh):\n",
    "    arr_oh = np.atleast_2d(arr_oh)\n",
    "    arr_le = np.vstack([decode_one_hot_row(r) for r in arr_oh])\n",
    "    preds  = dt.predict(arr_le)\n",
    "    classes= np.unique(y_train)\n",
    "    proba  = np.zeros((arr_oh.shape[0], classes.size))\n",
    "    for i,p in enumerate(preds):\n",
    "        proba[i, np.where(classes==p)[0][0]] = 1\n",
    "    return proba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e16a02d-849a-4a68-a654-44e362ff1be2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      8\u001b[39m explainer = LimeTabularExplainer(\n\u001b[32m      9\u001b[39m     training_data        = bg_data,\n\u001b[32m     10\u001b[39m     feature_names        = feature_names_oh,\n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m     random_state         = seed\n\u001b[32m     16\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m rep_idx:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     exp = \u001b[43mexplainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_test_oh\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# explain each **test** medoid\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdt_predict_proba\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m feat, wt \u001b[38;5;129;01min\u001b[39;00m exp.as_list(label=\u001b[32m1\u001b[39m):\n\u001b[32m     24\u001b[39m         agg_freq[feat]   += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:355\u001b[39m, in \u001b[36mLimeTabularExplainer.explain_instance\u001b[39m\u001b[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[39m\n\u001b[32m    348\u001b[39m     scaled_data = (data - \u001b[38;5;28mself\u001b[39m.scaler.mean_) / \u001b[38;5;28mself\u001b[39m.scaler.scale_\n\u001b[32m    349\u001b[39m distances = sklearn.metrics.pairwise_distances(\n\u001b[32m    350\u001b[39m         scaled_data,\n\u001b[32m    351\u001b[39m         scaled_data[\u001b[32m0\u001b[39m].reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m),\n\u001b[32m    352\u001b[39m         metric=distance_metric\n\u001b[32m    353\u001b[39m ).ravel()\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m yss = \u001b[43mpredict_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[38;5;66;03m# for classification, the model needs to provide a list of tuples - classes\u001b[39;00m\n\u001b[32m    358\u001b[39m \u001b[38;5;66;03m# along with prediction probabilities\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mclassification\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mdt_predict_proba\u001b[39m\u001b[34m(arr_oh)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdt_predict_proba\u001b[39m(arr_oh):\n\u001b[32m     16\u001b[39m     arr_oh = np.atleast_2d(arr_oh)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     arr_le = np.vstack(\u001b[43m[\u001b[49m\u001b[43mdecode_one_hot_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marr_oh\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     18\u001b[39m     preds  = dt.predict(arr_le)\n\u001b[32m     19\u001b[39m     classes= np.unique(y_train)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdt_predict_proba\u001b[39m(arr_oh):\n\u001b[32m     16\u001b[39m     arr_oh = np.atleast_2d(arr_oh)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     arr_le = np.vstack([\u001b[43mdecode_one_hot_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m arr_oh])\n\u001b[32m     18\u001b[39m     preds  = dt.predict(arr_le)\n\u001b[32m     19\u001b[39m     classes= np.unique(y_train)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mdecode_one_hot_row\u001b[39m\u001b[34m(row_oh)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, cat \u001b[38;5;129;01min\u001b[39;00m idxs_cats:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m row_oh[idx] == \u001b[32m1\u001b[39m:\n\u001b[32m     20\u001b[39m         \u001b[38;5;66;03m# encode that category back into the integer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m         decoded.append(\u001b[43mlabel_encoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m])\n\u001b[32m     22\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# if none ==1, maybe all zeros? default to most common\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:134\u001b[39m, in \u001b[36mLabelEncoder.transform\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) == \u001b[32m0\u001b[39m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray([])\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:235\u001b[39m, in \u001b[36m_encode\u001b[39m\u001b[34m(values, uniques, check_unknown)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xp.isdtype(values.dtype, \u001b[33m\"\u001b[39m\u001b[33mnumeric\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    237\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:173\u001b[39m, in \u001b[36m_map_to_integer\u001b[39m\u001b[34m(values, uniques)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Map values based on its position in uniques.\"\"\"\u001b[39;00m\n\u001b[32m    172\u001b[39m xp, _ = get_namespace(values, uniques)\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m table = \u001b[43m_nandict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43mval\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values], device=device(values))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[39m, in \u001b[36m_nandict.__init__\u001b[39m\u001b[34m(self, mapping)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mapping):\n\u001b[32m    158\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(mapping)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m mapping.items():\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m is_scalar_nan(key):\n\u001b[32m    161\u001b[39m             \u001b[38;5;28mself\u001b[39m.nan_value = value\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "from lime.lime_tabular        import LimeTabularExplainer\n",
    "\n",
    "# 4) aggregate exactly as before\n",
    "agg_freq, agg_wt = Counter(), defaultdict(float)\n",
    "for seed in (0,1,2):\n",
    "    explainer = LimeTabularExplainer(\n",
    "        training_data        = bg_data,\n",
    "        feature_names        = feature_names_oh,\n",
    "        class_names          = [\"edible\",\"poisonous\"],\n",
    "        mode                 = \"classification\",\n",
    "        categorical_features=list(range(bg_data.shape[1])),\n",
    "        discretize_continuous= False,\n",
    "        random_state         = seed\n",
    "    )\n",
    "    for idx in rep_idx:\n",
    "        exp = explainer.explain_instance(\n",
    "            X_test_oh[idx],    # explain each **test** medoid\n",
    "            dt_predict_proba,\n",
    "            num_features=6\n",
    "        )\n",
    "        for feat, wt in exp.as_list(label=1):\n",
    "            agg_freq[feat]   += 1\n",
    "            agg_wt[feat]     += wt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2054c27-de10-4fe0-b1b3-35bb35677d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature  pct_in_top5  mean_signed_weight\n",
      "5   odor_p=0    85.000000           -0.323165\n",
      "0   odor_f=0    80.000000           -0.843280\n",
      "6   odor_f=1    20.000000            0.843044\n",
      "9   odor_n=0     9.166667            0.096269\n",
      "11  odor_s=1     7.500000            0.326841\n",
      "8   odor_y=1     2.500000            0.325831\n",
      "12  odor_n=1     2.500000           -0.093546\n",
      "10  odor_a=1     2.500000           -0.349308\n",
      "7   odor_p=1     1.666667            0.324295\n",
      "13  odor_m=0     1.666667           -0.717493\n"
     ]
    }
   ],
   "source": [
    "from utils import text_utils\n",
    "\n",
    "# 5) build and save summary exactly as before\n",
    "k_total   = len(rep_idx)*3\n",
    "rows = [{\"feature\":f,\n",
    "         \"pct_in_top5\":100*agg_freq[f]/k_total,\n",
    "         \"mean_signed_weight\":agg_wt[f]/agg_freq[f]}\n",
    "        for f in agg_freq]\n",
    "summary_df = pd.DataFrame(rows).sort_values(\n",
    "    [\"pct_in_top5\",\"mean_signed_weight\"], ascending=False\n",
    ")\n",
    "text_utils.ensure_directory_exists(\"eval/lime_results\")\n",
    "summary_df.to_csv(\"eval/lime_results/lime_dt_summary1.csv\",index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(summary_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1212a3c6-541f-4aca-86cd-1809be42610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     feature  pct_in_top5  mean_signed_weight\n",
      "1   odor_c=0   100.000000           -0.625073\n",
      "3   odor_a=0    97.500000            0.349412\n",
      "4   odor_y=0    97.500000           -0.326303\n",
      "2   odor_s=0    92.500000           -0.324453\n",
      "5   odor_p=0    85.000000           -0.323165\n",
      "0   odor_f=0    80.000000           -0.843280\n",
      "6   odor_f=1    20.000000            0.843044\n",
      "9   odor_n=0     9.166667            0.096269\n",
      "11  odor_s=1     7.500000            0.326841\n",
      "8   odor_y=1     2.500000            0.325831\n",
      "12  odor_n=1     2.500000           -0.093546\n",
      "10  odor_a=1     2.500000           -0.349308\n",
      "7   odor_p=1     1.666667            0.324295\n",
      "13  odor_m=0     1.666667           -0.717493\n"
     ]
    }
   ],
   "source": [
    "print(summary_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
