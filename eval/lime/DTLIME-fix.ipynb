{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cdecbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\derri\\VSCode\\CS573MushroomProject\n"
     ]
    }
   ],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194ee92e-768b-4dfb-b655-6d2cdb41fdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "%run models/tree_impl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f94abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import text_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd627557-49c4-41a0-ae8f-608576064eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 100.00%\n",
      "Decision Tree Structure:\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Do your reproducible split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42,     stratify=y\n",
    "\n",
    ")\n",
    "\n",
    "# 2) Instantiate your custom tree (no args needed)\n",
    "from models.tree_impl import DecisionTreeClassifierCustom, print_tree\n",
    "dt = DecisionTreeClassifierCustom()\n",
    "\n",
    "# 3) Fit on the training slice\n",
    "dt.fit(X_train, y_train, feature_names)\n",
    "print(\"Decision Tree Structure:\")\n",
    "# print_tree(dt.tree, dt.original_feature_names)\n",
    "\n",
    "# 4) Evaluate on test\n",
    "print(\"Test accuracy:\", (dt.predict(X_test) == y_test).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4395d02-e7e7-4cd1-943c-060091630594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 1: One‑Hot Encode Train/Test Splits for Manhattan distance\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1) Reload raw data (strings) so we can one‑hot encode\n",
    "df_raw = pd.read_csv(\"data/mushroom_dataset.csv\")\n",
    "\n",
    "# 2) Create the same train/test split (stratified) on labels\n",
    "#    Using the y you already have from tree_impl, ensure it's the same order:\n",
    "X_all = df_raw.drop(columns=\"class\")\n",
    "y_all = df_raw[\"class\"]\n",
    "le = LabelEncoder().fit(df_raw[\"class\"])  # fits on all classes once\n",
    "y_all = le.transform(y_all)\n",
    "X_tr_raw, X_te_raw, y_train, y_test = train_test_split(\n",
    "    X_all, y_all,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y_all\n",
    ")\n",
    "\n",
    "# 3) One‑hot encode each split so distances are 0/1\n",
    "X_tr_oh = pd.get_dummies(X_tr_raw, columns=X_tr_raw.columns, drop_first=False)\n",
    "X_te_oh = pd.get_dummies(X_te_raw, columns=X_te_raw.columns, drop_first=False)\n",
    "\n",
    "# 4) Align columns (in case some rare category only appears in test)\n",
    "all_cols = sorted(set(X_tr_oh.columns).union(X_te_oh.columns))\n",
    "X_tr_oh = X_tr_oh.reindex(columns=all_cols, fill_value=0)\n",
    "X_te_oh = X_te_oh.reindex(columns=all_cols, fill_value=0)\n",
    "\n",
    "# 5) Grab numpy arrays & feature names\n",
    "X_train_oh = X_tr_oh.values\n",
    "X_test_oh  = X_te_oh.values\n",
    "feature_names_oh = all_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80aec666-ac14-41da-980a-4bf641ede5cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.46 MiB for an array with shape (5000, 117) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     60\u001b[39m explainer = LimeTabularExplainer(\n\u001b[32m     61\u001b[39m     training_data         = bg,\n\u001b[32m     62\u001b[39m     feature_names         = feature_names_oh,\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     random_state          = seed\n\u001b[32m     67\u001b[39m )\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m md:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     exp = \u001b[43mexplainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdt_proba_oh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# ask for all, so we can filter safely\u001b[39;49;00m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     raw = exp.as_list(label=np.argmax(dt_proba_oh(row.reshape(\u001b[32m1\u001b[39m,-\u001b[32m1\u001b[39m))[\u001b[32m0\u001b[39m]))\n\u001b[32m     75\u001b[39m     count = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:452\u001b[39m, in \u001b[36mLimeTabularExplainer.explain_instance\u001b[39m\u001b[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[39m\n\u001b[32m    448\u001b[39m     labels = [\u001b[32m0\u001b[39m]\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels:\n\u001b[32m    450\u001b[39m     (ret_exp.intercept[label],\n\u001b[32m    451\u001b[39m      ret_exp.local_exp[label],\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m      ret_exp.score, ret_exp.local_pred) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexplain_instance_with_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m            \u001b[49m\u001b[43mscaled_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m            \u001b[49m\u001b[43myss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_regressor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_regressor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mregression\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    462\u001b[39m     ret_exp.intercept[\u001b[32m1\u001b[39m] = ret_exp.intercept[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\lime\\lime_base.py:183\u001b[39m, in \u001b[36mLimeBase.explain_instance_with_data\u001b[39m\u001b[34m(self, neighborhood_data, neighborhood_labels, distances, label, num_features, feature_selection, model_regressor)\u001b[39m\n\u001b[32m    181\u001b[39m weights = \u001b[38;5;28mself\u001b[39m.kernel_fn(distances)\n\u001b[32m    182\u001b[39m labels_column = neighborhood_labels[:, label]\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m used_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneighborhood_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mlabels_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m                                       \u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_regressor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    189\u001b[39m     model_regressor = Ridge(alpha=\u001b[32m1\u001b[39m, fit_intercept=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    190\u001b[39m                             random_state=\u001b[38;5;28mself\u001b[39m.random_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\lime\\lime_base.py:134\u001b[39m, in \u001b[36mLimeBase.feature_selection\u001b[39m\u001b[34m(self, data, labels, weights, num_features, method)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    133\u001b[39m     n_method = \u001b[33m'\u001b[39m\u001b[33mhighest_weights\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_method\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\lime\\lime_base.py:80\u001b[39m, in \u001b[36mLimeBase.feature_selection\u001b[39m\u001b[34m(self, data, labels, weights, num_features, method)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m'\u001b[39m\u001b[33mhighest_weights\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     78\u001b[39m     clf = Ridge(alpha=\u001b[32m0.01\u001b[39m, fit_intercept=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     79\u001b[39m                 random_state=\u001b[38;5;28mself\u001b[39m.random_state)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     coef = clf.coef_\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sp.sparse.issparse(data):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:1249\u001b[39m, in \u001b[36mRidge.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1238\u001b[39m xp, _ = get_namespace(X, y, sample_weight)\n\u001b[32m   1239\u001b[39m X, y = validate_data(\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1241\u001b[39m     X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1247\u001b[39m     y_numeric=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1248\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:956\u001b[39m, in \u001b[36m_BaseRidge.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    953\u001b[39m     sample_weight = _check_sample_weight(sample_weight, X, dtype=X.dtype)\n\u001b[32m    955\u001b[39m \u001b[38;5;66;03m# when X is sparse we only remove offset from y\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m X, y, X_offset, y_offset, X_scale = \u001b[43m_preprocess_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m solver == \u001b[33m\"\u001b[39m\u001b[33msag\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sparse.issparse(X) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit_intercept:\n\u001b[32m    965\u001b[39m     \u001b[38;5;28mself\u001b[39m.coef_, \u001b[38;5;28mself\u001b[39m.n_iter_, \u001b[38;5;28mself\u001b[39m.intercept_, \u001b[38;5;28mself\u001b[39m.solver_ = _ridge_regression(\n\u001b[32m    966\u001b[39m         X,\n\u001b[32m    967\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    978\u001b[39m         check_input=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    979\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:166\u001b[39m, in \u001b[36m_preprocess_data\u001b[39m\u001b[34m(X, y, fit_intercept, copy, copy_y, sample_weight, check_input)\u001b[39m\n\u001b[32m    163\u001b[39m     sample_weight = xp.asarray(sample_weight)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_input:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m     y = check_array(y, dtype=X.dtype, copy=copy_y, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1118\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m     \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n\u001b[32m   1117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.may_share_memory(array, array_orig):\n\u001b[32m-> \u001b[39m\u001b[32m1118\u001b[39m         array = \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1122\u001b[39m     \u001b[38;5;66;03m# always make a copy for non-numpy arrays\u001b[39;00m\n\u001b[32m   1123\u001b[39m     array = _asarray_with_order(\n\u001b[32m   1124\u001b[39m         array, dtype=dtype, order=order, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, xp=xp\n\u001b[32m   1125\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\derri\\VSCode\\CS573MushroomProject\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:837\u001b[39m, in \u001b[36m_asarray_with_order\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m    835\u001b[39m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    836\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m         array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    839\u001b[39m         array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 4.46 MiB for an array with shape (5000, 117) and data type float64"
     ]
    }
   ],
   "source": [
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Cell X: One‐hot + filtered LIME summary for Decision Tree\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from lime.lime_tabular      import LimeTabularExplainer\n",
    "from collections            import Counter, defaultdict\n",
    "\n",
    "# — your pre‑existing variables —\n",
    "# X_train_oh      : np.ndarray, one‐hot encoded training data (n_train × d)\n",
    "# X_test_oh       : np.ndarray, one‐hot encoded test data  (n_test  × d)\n",
    "# feature_names_oh: list of length d, the one‐hot column names\n",
    "# tree_classifier : your fitted DecisionTreeClassifierCustom\n",
    "# y_train         : train labels (0/1)\n",
    "# (make sure you’ve run the cells that create all of the above)\n",
    "\n",
    "# 1) Cluster medoids on the one‐hot test set\n",
    "kmed   = KMedoids(n_clusters=40, metric=\"manhattan\", random_state=0)\n",
    "kmed.fit(X_test_oh)\n",
    "rep_idx = kmed.medoid_indices_\n",
    "\n",
    "# 2) Define background & medoids\n",
    "bg = X_train_oh            # LIME’s background\n",
    "md = X_test_oh[rep_idx]    # the 40 held‐out medoids\n",
    "\n",
    "# 3) Mark every one‐hot column as categorical\n",
    "cat_feats = list(range(bg.shape[1]))\n",
    "\n",
    "# 4) A wrapper that maps one‐hot → label vector → tree predict_proba\n",
    "def dt_proba_oh(arr_oh):\n",
    "    arr_oh = np.atleast_2d(arr_oh)\n",
    "    # decode one‐hot to label‐encoded integers\n",
    "    from models.tree_impl import label_encoders, feature_names\n",
    "    X_le = []\n",
    "    for row in arr_oh:\n",
    "        decoded = []\n",
    "        idx = 0\n",
    "        for feat in feature_names:\n",
    "            le = label_encoders[feat]\n",
    "            n_cats = len(le.classes_)\n",
    "            block = row[idx:idx+n_cats]\n",
    "            decoded.append(int(np.argmax(block)))\n",
    "            idx += n_cats\n",
    "        X_le.append(decoded)\n",
    "    X_le = np.array(X_le)\n",
    "    # predict and build a 2‐col proba array\n",
    "    preds = tree_classifier.predict(X_le)\n",
    "    proba = np.zeros((len(preds), 2))\n",
    "    for i,p in enumerate(preds):\n",
    "        proba[i, int(p)] = 1\n",
    "    return proba\n",
    "\n",
    "# 5) Run LIME on each medoid × 3 seeds, filter out dummy=0  \n",
    "agg_freq, agg_wt = Counter(), defaultdict(float)\n",
    "seeds = [0,1,2]\n",
    "for seed in seeds:\n",
    "    explainer = LimeTabularExplainer(\n",
    "        training_data         = bg,\n",
    "        feature_names         = feature_names_oh,\n",
    "        class_names           = [\"edible\",\"poisonous\"],\n",
    "        categorical_features  = cat_feats,\n",
    "        discretize_continuous = False,\n",
    "        random_state          = seed\n",
    "    )\n",
    "    for row in md:\n",
    "        exp = explainer.explain_instance(\n",
    "            row,\n",
    "            dt_proba_oh,\n",
    "            num_features=bg.shape[1]   # ask for all, so we can filter safely\n",
    "        )\n",
    "        raw = exp.as_list(label=np.argmax(dt_proba_oh(row.reshape(1,-1))[0]))\n",
    "        count = 0\n",
    "        for feat_val, wt in raw:\n",
    "            feat = feat_val.split(\"=\",1)[0]        # strip “=0” or “=1”\n",
    "            idx  = feature_names_oh.index(feat)\n",
    "            if row[idx] == 1:                      # only keep actual 1’s\n",
    "                agg_freq[feat] += 1\n",
    "                agg_wt[feat]   += wt\n",
    "                count += 1\n",
    "                if count == 5:                     # top 5 only\n",
    "                    break\n",
    "\n",
    "# 6) Build and print the summary DataFrame\n",
    "k_total = len(md) * len(seeds)  # 40 × 3 = 120 runs\n",
    "rows = []\n",
    "for feat, freq in agg_freq.items():\n",
    "    rows.append({\n",
    "        \"feature\":            feat,\n",
    "        \"pct_in_top5\":       100 * freq      / k_total,\n",
    "        \"mean_signed_weight\": agg_wt[feat]   / freq\n",
    "    })\n",
    "summary_df = pd.DataFrame(rows).sort_values(\n",
    "    [\"pct_in_top5\",\"mean_signed_weight\"],\n",
    "    ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(summary_df)\n",
    "text_utils.ensure_directory_exists(\"eval/lime_results\")\n",
    "summary_df.to_csv(\"eval/lime_results/lime_dt_summary_filtered.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1212a3c6-541f-4aca-86cd-1809be42610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature  pct_in_top5  mean_signed_weight\n",
      "0            gill-attachment_f   100.000000            0.583016\n",
      "1                 veil-color_w    59.166667           -0.000653\n",
      "2                ring-number_o    36.666667            0.000257\n",
      "3                 gill-color_n    24.166667            0.015249\n",
      "4                 gill-color_b    15.000000            0.018897\n",
      "..                         ...          ...                 ...\n",
      "61                stalk-root_e     0.833333            0.004677\n",
      "62  stalk-surface-above-ring_f     0.833333           -0.004816\n",
      "63                population_s     0.833333           -0.005291\n",
      "64                 gill-size_n     0.833333           -0.005469\n",
      "65                   habitat_m     0.833333           -0.005721\n",
      "\n",
      "[66 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(summary_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
