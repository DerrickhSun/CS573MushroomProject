{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fe45c5-510c-439e-a740-e84be5634e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, importlib.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# 1) Dynamically load your teammate’s module\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"nbc_mod\", os.path.join(os.getcwd(), \"nbc.py\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5be0c5-f428-4be8-909e-1938288183ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nbc_mod = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(nbc_mod)  \n",
    "\n",
    "# 2) Load & preprocess\n",
    "df = pd.read_csv(\"mushroom_dataset.csv\")\n",
    "X, y, encoders = nbc_mod.preprocess_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a813a5e3-2009-4692-830c-f46d55d972bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47af4745-594c-4df2-8bed-5a43b2ad5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Train the custom NBC\n",
    "nbc = nbc_mod.NBC()\n",
    "nbc.train(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a2362eb-daae-488d-9a31-2b5a62042d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Build a predict_proba wrapper\n",
    "def predict_proba_custom(arr):\n",
    "    \"\"\"\n",
    "    arr: numpy array of shape (n_samples, n_features)\n",
    "    returns: array of shape (n_samples, n_classes)\n",
    "    \"\"\"\n",
    "    df_in = pd.DataFrame(arr, columns=X_train.columns)\n",
    "    probs = []\n",
    "    for _, row in df_in.iterrows():\n",
    "        # use predict_one to get (class, raw_score)\n",
    "        # but we need all class raw scores\n",
    "        # so we’ll reimplement the core loop here:\n",
    "        raw = {}\n",
    "        for c in nbc.output_classes:\n",
    "            p = nbc.output_class_probs[c]\n",
    "            for ft, val in row.items():\n",
    "                p *= nbc.per_class_feature_probs[c][ft][val]\n",
    "            raw[c] = p\n",
    "        # normalize\n",
    "        total = sum(raw.values())\n",
    "        probs.append([ raw[c]/total for c in nbc.output_classes ])\n",
    "    return np.array(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c8919b-ce26-495c-86a8-713845c55858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom NBC test accuracy: 0.9458572600492207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Quick sanity check\n",
    "print(\"Custom NBC test accuracy:\",\n",
    "      np.mean(nbc.predict(X_test) == y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55e99da1-5c32-4a71-996c-55a7ecc18585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Set up LIME with categorical metadata\n",
    "feature_names        = X_train.columns.tolist()\n",
    "categorical_features = list(range(len(feature_names)))\n",
    "categorical_names    = {\n",
    "    i: encoders[col].classes_.tolist()\n",
    "    for i, col in enumerate(feature_names)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "075ea4e5-e599-498e-b234-93804ed3d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data         = X_train.values,\n",
    "    feature_names         = feature_names,\n",
    "    class_names           = [str(c) for c in nbc.output_classes],\n",
    "    mode                  = \"classification\",\n",
    "    categorical_features  = categorical_features,\n",
    "    categorical_names     = categorical_names,\n",
    "    discretize_continuous = False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc7108a3-c67e-4bd5-a95a-0501efed6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Explain a test instance (e.g. index 0)\n",
    "idx = 1\n",
    "exp = explainer.explain_instance(\n",
    "    data_row     = X_test.iloc[idx].values,\n",
    "    predict_fn   = predict_proba_custom,\n",
    "    num_features = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b0e0341-2dfb-42cf-a2d0-9a8ea5c8ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LIME explanation for custom NBC instance #1:\n",
      "  gill-color=b: 0.3109\n",
      "  odor=y: 0.2485\n",
      "  gill-size=n: 0.1262\n",
      "  stalk-surface-above-ring=s: -0.1078\n",
      "  population=v: 0.1017\n",
      "Saved HTML → lime_custom_nbc_1.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"\\nLIME explanation for custom NBC instance #{idx}:\")\n",
    "for feat, w in exp.as_list():\n",
    "    print(f\"  {feat}: {w:.4f}\")\n",
    "\n",
    "exp.save_to_file(f\"lime_custom_nbc_{idx}.html\")\n",
    "print(f\"Saved HTML → lime_custom_nbc_{idx}.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec51f39d-a5dc-4e21-b3ec-76cb7ef3456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "#  LIME-on-k–medoids  pipeline  (one‑hot version)\n",
    "# ------------------------------------------------------------------\n",
    "import pandas as pd, numpy as np, joblib, json\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn_extra.cluster import KMedoids          # pip install scikit-learn-extra\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from collections import defaultdict, Counter\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from packaging import version\n",
    "\n",
    "\n",
    "# ---------- 1. one‑hot encode the original df ---------------------\n",
    "df = pd.read_csv(\"mushroom_dataset.csv\")\n",
    "y_full = df[\"class\"].map({\"e\": 0, \"p\": 1}).to_numpy()\n",
    "X_raw  = df.drop(columns=\"class\")\n",
    "\n",
    "\n",
    "if version.parse(sklearn.__version__) >= version.parse(\"1.2\"):\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "else:\n",
    "    ohe = OneHotEncoder(sparse=False,       handle_unknown=\"ignore\")\n",
    "\n",
    "X_onehot = ohe.fit_transform(X_raw)\n",
    "onehot_feature_names = ohe.get_feature_names_out(X_raw.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2019cef6-ee99-4c88-8329-f63cae526d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- 2. train/test split (same split as your NBC) ----------\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te, idx_tr, idx_te = train_test_split(\n",
    "    X_onehot, y_full, np.arange(len(y_full)),\n",
    "    test_size=0.3, random_state=42, stratify=y_full\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66a6e360-fdd1-4635-a080-7f1d26d02991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1.  LOAD & SPLIT DATA  (label‑encoded + one‑hot)\n",
    "# ---------------------------------------------------------------\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.utils import Bunch\n",
    "from nbc import NBC           # your custom Naive Bayes class\n",
    "\n",
    "df = pd.read_csv(\"mushroom_dataset.csv\")\n",
    "X_raw, y_raw = df.drop(columns=\"class\"), df[\"class\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d23cc773-b493-49d3-900f-818e63260c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- label‑encode every column (NBC needs this) ---\n",
    "X_le = X_raw.copy()\n",
    "encoders = {}\n",
    "for col in X_le.columns:\n",
    "    le = LabelEncoder().fit(X_le[col])\n",
    "    X_le[col] = le.transform(X_le[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "y = y_raw.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eb922fb-9306-4a8e-85b7-df2ef4f5e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- one‑hot encode for distance / LIME ---\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "X_oh = ohe.fit_transform(X_raw)\n",
    "onehot_names = ohe.get_feature_names_out(X_raw.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd9d190c-a6b1-4aba-a317-0e19532134e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# one single split so rows align\n",
    "X_le_tr, X_le_te, X_oh_tr, X_oh_te, y_tr, y_te = train_test_split(\n",
    "    X_le, X_oh, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3869c9e7-c490-401d-aec1-20d93642408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2.  TRAIN NBC ON LABEL‑ENCODED TRAIN DATA\n",
    "# ---------------------------------------------------------------\n",
    "nbc = NBC()\n",
    "nbc.train(X_le_tr, y_tr)          # custom implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50d2207f-090b-4236-a54b-91a4903f0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 3.  PICK k MEDOIDS (or K‑means) ON ONE‑HOT TEST MATRIX\n",
    "# ---------------------------------------------------------------\n",
    "k = 40\n",
    "try:\n",
    "    from sklearn_extra.cluster import KMedoids\n",
    "    med = KMedoids(n_clusters=k, metric=\"manhattan\", random_state=0).fit(X_oh_te)\n",
    "    rep_idx_te = med.medoid_indices_            # indices within X_oh_te\n",
    "except ImportError:\n",
    "    # fallback: K‑means + closest point to each centroid\n",
    "    from sklearn.cluster import KMeans\n",
    "    km = KMeans(n_clusters=k, random_state=0, n_init='auto').fit(X_oh_te)\n",
    "    from sklearn.metrics import pairwise_distances_argmin\n",
    "    rep_idx_te = pairwise_distances_argmin(km.cluster_centers_, X_oh_te)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86c8d407-1e46-42a3-b95c-69269f89d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get corresponding rows in each representation\n",
    "X_oh_reps = X_oh_te[rep_idx_te]\n",
    "X_le_reps = X_le_te.iloc[rep_idx_te]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd92aae0-9123-4c9e-8a52-d5ee49ee8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 4.  LIME ON EACH REPRESENTATIVE POINT (3 seeds each)\n",
    "# ---------------------------------------------------------------\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_oh_tr,\n",
    "    feature_names=onehot_names,\n",
    "    class_names=[\"edible\", \"poisonous\"],\n",
    "    discretize_continuous=False\n",
    ")\n",
    "def make_explainer(seed):\n",
    "    return LimeTabularExplainer(\n",
    "        X_oh_tr,\n",
    "        feature_names=onehot_names,\n",
    "        class_names=[\"edible\", \"poisonous\"],\n",
    "        discretize_continuous=False,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b85f236d-29f8-46d7-a036-3f22769cd1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_proba(X_oh_batch):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_oh_batch : ndarray (n_samples, n_onehot_features)\n",
    "        0/1 one‑hot rows supplied by LIME.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    probs : ndarray (n_samples, 2)\n",
    "        Columns: P(edible) , P(poisonous)\n",
    "    \"\"\"\n",
    "    # --- 1. one‑hot  ➜  original string categories -------------\n",
    "    cat_matrix = ohe.inverse_transform(X_oh_batch)   # shape (n_samples, 117)\n",
    "\n",
    "    # --- 2. string categories  ➜  label‑encoded ints -----------\n",
    "    #     vectorised column‑by‑column\n",
    "    le_matrix = np.empty_like(cat_matrix, dtype=int)\n",
    "    for j, col in enumerate(X_raw.columns):\n",
    "        le_matrix[:, j] = encoders[col].transform(cat_matrix[:, j])\n",
    "\n",
    "    # --- 3. NBC probability for each row -----------------------\n",
    "    prob_e = []\n",
    "    prob_p = []\n",
    "    for row in le_matrix:\n",
    "        # row is a 1‑D int array; wrap in dict {feature: value}\n",
    "        entry = dict(zip(X_raw.columns, row))\n",
    "        # use your NBC's predict_one, which returns (class, prob)\n",
    "        pred_class, pred_prob = nbc.predict_one(entry)\n",
    "\n",
    "        # compute the *unnormalised* probs for each class\n",
    "        unnorm = {}\n",
    "        for cls in nbc.output_classes:\n",
    "            p = nbc.output_class_probs[cls]\n",
    "            for ft, val in entry.items():\n",
    "                p *= nbc.per_class_feature_probs[cls][ft][val]\n",
    "            unnorm[cls] = p\n",
    "        total = unnorm['e'] + unnorm['p']\n",
    "        prob_e.append(unnorm['e'] / total)\n",
    "        prob_p.append(unnorm['p'] / total)\n",
    "\n",
    "    return np.column_stack([prob_e, prob_p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "affcef90-1fe8-4a1d-9149-5daa59580f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = (0, 1, 2)\n",
    "agg_freq, agg_weight = Counter(), defaultdict(float)\n",
    "\n",
    "for oh_row in X_oh_reps:\n",
    "    for sd in seeds:\n",
    "        exp = make_explainer(sd).explain_instance(\n",
    "            oh_row,\n",
    "            model_proba,\n",
    "            num_features=5\n",
    "        )\n",
    "        for feat, weight in exp.as_list():\n",
    "            agg_freq[feat] += 1\n",
    "            agg_weight[feat] += weight\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31b3fa70-2812-4a81-a05c-df27fe5b3cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ wrote lime_nbc_summary.csv with 6 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5.  SUMMARY CSV\n",
    "# ---------------------------------------------------------------\n",
    "k_total = k * len(seeds)\n",
    "rows = [\n",
    "    {\n",
    "        \"feature\": f,\n",
    "        \"pct_in_top5\": 100 * agg_freq[f] / k_total,\n",
    "        \"mean_signed_weight\": agg_weight[f] / agg_freq[f],\n",
    "    }\n",
    "    for f in agg_freq\n",
    "]\n",
    "summary_df = pd.DataFrame(rows).sort_values(\n",
    "    [\"pct_in_top5\", \"mean_signed_weight\"], ascending=False\n",
    ")\n",
    "summary_df.to_csv(\"lime_nbc_summary1.csv\", index=False)\n",
    "print(\"sweet it worked: wrote lime_nbc_summary.csv with\", len(summary_df), \"rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b1c1b-5dbf-42c5-8c2a-45911b3fa4e0",
   "metadata": {},
   "source": [
    "odor_f\t100 %\t+0.106\t“Odor = foul” is in every explanation and increases the NBC’s confidence in the predicted class (almost always poisonous). It’s the model’s strongest universal cue.\n",
    "gill‑color_b\t100 %\t+0.088\tHaving brown gills consistently supports the prediction (likely poisonous).\n",
    "ring‑type_l\t100 %\t+0.053\tLarge ring type also pushes probability toward the predicted class.\n",
    "odor_n\t100 %\t‑0.132\t“Odor = none” appears everywhere but with a negative effect – it pulls the model away from the current prediction. That usually means the model uses odor = none as evidence against poison.\n",
    "ring‑type_p\t98 %\t‑0.050\tPartial ring is almost everywhere and slightly decreases confidence; perhaps NBC associates partial rings with edible mushrooms.\n",
    "spore‑print‑color_h\t1.7 %\t+0.041\t“Spore‑print = chocolate” (value h) barely shows up (only 2 runs out of 120) so it’s not a globally important cue, but when it does appear it nudges the probability up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
