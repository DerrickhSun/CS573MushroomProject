{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26fe45c5-510c-439e-a740-e84be5634e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, importlib.util\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# 1) Dynamically load your teammate’s module\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"nbc_mod\", os.path.join(os.getcwd(), \"nbc.py\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a5be0c5-f428-4be8-909e-1938288183ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nbc_mod = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(nbc_mod)  \n",
    "\n",
    "# 2) Load & preprocess\n",
    "df = pd.read_csv(\"data/mushroom_dataset.csv\")\n",
    "X, y, encoders = nbc_mod.preprocess_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a813a5e3-2009-4692-830c-f46d55d972bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47af4745-594c-4df2-8bed-5a43b2ad5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Train the custom NBC\n",
    "nbc = nbc_mod.NBC()\n",
    "nbc.train(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c8919b-ce26-495c-86a8-713845c55858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom NBC test accuracy: 0.9458572600492207\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Quick sanity check\n",
    "print(\"Custom NBC test accuracy:\",\n",
    "      np.mean(nbc.predict(X_test) == y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec51f39d-a5dc-4e21-b3ec-76cb7ef3456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "#  LIME-on-k–medoids  pipeline  (one‑hot version)\n",
    "# ------------------------------------------------------------------\n",
    "import pandas as pd, numpy as np, joblib, json\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn_extra.cluster import KMedoids          # pip install scikit-learn-extra\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from collections import defaultdict, Counter\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from packaging import version\n",
    "\n",
    "\n",
    "# ---------- 1. one‑hot encode the original df ---------------------\n",
    "df = pd.read_csv(\"data/mushroom_dataset.csv\")\n",
    "y_full = df[\"class\"].map({\"e\": 0, \"p\": 1}).to_numpy()\n",
    "X_raw  = df.drop(columns=\"class\")\n",
    "\n",
    "\n",
    "if version.parse(sklearn.__version__) >= version.parse(\"1.2\"):\n",
    "    ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "else:\n",
    "    ohe = OneHotEncoder(sparse=False,       handle_unknown=\"ignore\")\n",
    "\n",
    "X_onehot = ohe.fit_transform(X_raw)\n",
    "onehot_feature_names = ohe.get_feature_names_out(X_raw.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2019cef6-ee99-4c88-8329-f63cae526d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- 2. train/test split (same split as your NBC) ----------\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te, idx_tr, idx_te = train_test_split(\n",
    "    X_onehot, y_full, np.arange(len(y_full)),\n",
    "    test_size=0.3, random_state=42, stratify=y_full\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66a6e360-fdd1-4635-a080-7f1d26d02991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1.  LOAD & SPLIT DATA  (label‑encoded + one‑hot)\n",
    "# ---------------------------------------------------------------\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.utils import Bunch\n",
    "from nbc import NBC           # your custom Naive Bayes class\n",
    "\n",
    "df = pd.read_csv(\"data/mushroom_dataset.csv\")\n",
    "X_raw, y_raw = df.drop(columns=\"class\"), df[\"class\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d23cc773-b493-49d3-900f-818e63260c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- label‑encode every column (NBC needs this) ---\n",
    "X_le = X_raw.copy()\n",
    "encoders = {}\n",
    "for col in X_le.columns:\n",
    "    le = LabelEncoder().fit(X_le[col])\n",
    "    X_le[col] = le.transform(X_le[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "y = y_raw.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eb922fb-9306-4a8e-85b7-df2ef4f5e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- one‑hot encode for distance / LIME ---\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "X_oh = ohe.fit_transform(X_raw)\n",
    "onehot_names = ohe.get_feature_names_out(X_raw.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd9d190c-a6b1-4aba-a317-0e19532134e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# one single split so rows align\n",
    "X_le_tr, X_le_te, X_oh_tr, X_oh_te, y_tr, y_te = train_test_split(\n",
    "    X_le, X_oh, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c8cab59-1cb2-406a-86ee-3225e19ee159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick 40 medoids on the ONE‑HOT test set\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "kmed   = KMedoids(n_clusters=40, metric=\"manhattan\", random_state=0)\n",
    "kmed.fit(X_oh_te)\n",
    "rep_idx = kmed.medoid_indices_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8a4fbf6-1dab-4dc9-98d1-fa38ea1961b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature  pct_in_top5  mean_signed_weight\n",
      "1                  ring-type=p    67.500000           -0.154501\n",
      "4   stalk-surface-above-ring=s    66.666667           -0.120916\n",
      "0                       odor=n    62.500000           -0.379259\n",
      "3                  gill-size=b    52.500000           -0.122882\n",
      "5                 population=v    35.833333            0.112640\n",
      "6   stalk-surface-below-ring=s    21.666667           -0.111141\n",
      "9                       odor=f    20.000000            0.389031\n",
      "24  stalk-surface-above-ring=k    17.500000            0.150217\n",
      "21  stalk-surface-below-ring=k    15.833333            0.145587\n",
      "10                gill-color=b    15.000000            0.309639\n",
      "22                 ring-type=l    15.000000            0.274615\n",
      "8                    bruises=t    15.000000           -0.108866\n",
      "23         spore-print-color=h    14.166667            0.166090\n",
      "13                 gill-size=n    14.166667            0.123816\n",
      "20         spore-print-color=n    11.666667           -0.126037\n",
      "25                      odor=s     7.500000            0.269457\n",
      "15                   bruises=f     7.500000            0.104201\n",
      "2          spore-print-color=k     7.500000           -0.131405\n",
      "12                gill-color=n     7.500000           -0.158451\n",
      "17    stalk-color-above-ring=g     7.500000           -0.269435\n",
      "14                      odor=y     2.500000            0.258694\n",
      "19                population=n     2.500000           -0.237136\n",
      "7     stalk-color-below-ring=g     2.500000           -0.279470\n",
      "16                      odor=l     2.500000           -0.330409\n",
      "18                      odor=a     2.500000           -0.343306\n",
      "28              gill-spacing=c     1.666667            0.136931\n",
      "27                population=a     1.666667           -0.231308\n",
      "26                gill-color=w     0.833333           -0.120631\n",
      "11              gill-spacing=w     0.833333           -0.133613\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 13: LIME in label‑encoded space for NBC (feature=value style)\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lime.lime_tabular  import LimeTabularExplainer\n",
    "from collections        import Counter, defaultdict\n",
    "from utils import text_utils\n",
    "\n",
    "# 1) We already did:\n",
    "#    X_le_tr, X_le_te, X_oh_tr, X_oh_te, y_tr, y_te = train_test_split(...)\n",
    "#    encoders = {col: LabelEncoder()… }  # from Cell 8\n",
    "#    ohe      = OneHotEncoder()…         # from Cell 9\n",
    "#    nbc.train(X_le_tr, y_tr)            # earlier cell\n",
    "\n",
    "# 2) Pick 40 medoids on the ONE‑HOT test set (Cell 12)\n",
    "#    (we reuse its rep_idx)\n",
    "# rep_idx = kmed.medoid_indices_\n",
    "\n",
    "# 3) Build label‑encoded arrays\n",
    "bg_le  = X_le_tr.values                  # train background in label space\n",
    "med_le = X_le_te.values[rep_idx]         # the 40 test medoids in label space\n",
    "\n",
    "# 4) Tell LIME these d are all categorical features\n",
    "d = bg_le.shape[1]\n",
    "cat_feats = list(range(d))\n",
    "cat_names  = {\n",
    "    i: encoders[col].classes_.tolist()\n",
    "    for i, col in enumerate(X_le_tr.columns)\n",
    "}\n",
    "\n",
    "# 5) Wrap your NBC so it returns [P(edible), P(poisonous)] on label‑encoded rows\n",
    "def model_proba_le(arr_le):\n",
    "    arr = np.atleast_2d(arr_le)\n",
    "    prob_e, prob_p = [], []\n",
    "    for sample in arr:\n",
    "        # reconstruct a pandas Series for your predict_one\n",
    "        entry = pd.Series({col: sample[i]\n",
    "                           for i, col in enumerate(X_le_tr.columns)})\n",
    "        # compute unnormalised class‑likelihoods just as in model_proba\n",
    "        unnorm = {}\n",
    "        for cls in nbc.output_classes:\n",
    "            p0 = nbc.output_class_probs[cls]\n",
    "            for ft, val in entry.items():\n",
    "                p0 *= nbc.per_class_feature_probs[cls][ft][val]\n",
    "            unnorm[cls] = p0\n",
    "        # normalise\n",
    "        total = sum(unnorm.values())\n",
    "        prob_e.append(unnorm['e'] / total)\n",
    "        prob_p.append(unnorm['p'] / total)\n",
    "    return np.column_stack([prob_e, prob_p])\n",
    "\n",
    "# 6) Run LIME on each medoid × 3 seeds, aggregate top‑5 hits\n",
    "agg_freq, agg_wt = Counter(), defaultdict(float)\n",
    "for seed in (0, 1, 2):\n",
    "    explainer = LimeTabularExplainer(\n",
    "        training_data        = bg_le,\n",
    "        feature_names        = list(X_le_tr.columns),\n",
    "        class_names          = [\"edible\",\"poisonous\"],\n",
    "        categorical_features = cat_feats,\n",
    "        categorical_names    = cat_names,\n",
    "        mode                 = \"classification\",\n",
    "        random_state         = seed\n",
    "    )\n",
    "    for row in med_le:\n",
    "        exp = explainer.explain_instance(\n",
    "            row,\n",
    "            model_proba_le,\n",
    "            num_features=5\n",
    "        )\n",
    "        for feat, wt in exp.as_list(label=1):\n",
    "            agg_freq[feat] += 1\n",
    "            agg_wt[feat]   += wt\n",
    "\n",
    "# 7) Build your summary table just like before\n",
    "k_total = len(rep_idx) * 3  # 40 medoids × 3 seeds\n",
    "rows = []\n",
    "for feat in agg_freq:\n",
    "    rows.append({\n",
    "        \"feature\":            feat,\n",
    "        \"pct_in_top5\":       100 * agg_freq[feat]   / k_total,\n",
    "        \"mean_signed_weight\": agg_wt[feat]         / agg_freq[feat]\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(rows).sort_values(\n",
    "    [\"pct_in_top5\", \"mean_signed_weight\"],\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(summary_df)\n",
    "\n",
    "text_utils.ensure_directory_exists(\"eval/lime_results\")\n",
    "summary_df.to_csv(\"eval/lime_results/lime_nbc_summary_label_encoded.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869c9e7-c490-401d-aec1-20d93642408c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2.  TRAIN NBC ON LABEL‑ENCODED TRAIN DATA\n",
    "# ---------------------------------------------------------------\n",
    "nbc = NBC()\n",
    "nbc.train(X_le_tr, y_tr)          # custom implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d2207f-090b-4236-a54b-91a4903f0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 3.  PICK k MEDOIDS (or K‑means) ON ONE‑HOT TEST MATRIX\n",
    "# ---------------------------------------------------------------\n",
    "kmed    = KMedoids(n_clusters=40, metric=\"manhattan\", random_state=0)\n",
    "kmed.fit(X_oh_te)\n",
    "rep_idx = kmed.medoid_indices_\n",
    "\n",
    "# (3) Build label‑encoded background & medoids\n",
    "bg_le   = X_le_tr.values      # shape (n_train, d)\n",
    "med_le  = X_le_te.values[rep_idx]  # shape (40, d)\n",
    "\n",
    "# (4) Setup LIME on label‑encoded data\n",
    "d = bg_le.shape[1]\n",
    "cat_feats = list(range(d))\n",
    "cat_names = {\n",
    "    i: label_encoders[col].classes_.tolist()\n",
    "    for i, col in enumerate(X_le_tr.columns)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c8d407-1e46-42a3-b95c-69269f89d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get corresponding rows in each representation\n",
    "X_oh_reps = X_oh_te[rep_idx_te]\n",
    "X_le_reps = X_le_te.iloc[rep_idx_te]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92aae0-9123-4c9e-8a52-d5ee49ee8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# 4.  LIME ON EACH REPRESENTATIVE POINT (3 seeds each)\n",
    "# ---------------------------------------------------------------\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=X_oh_tr,\n",
    "    feature_names=onehot_names,\n",
    "    class_names=[\"edible\", \"poisonous\"],\n",
    "    discretize_continuous=False\n",
    ")\n",
    "def make_explainer(seed):\n",
    "    return LimeTabularExplainer(\n",
    "        X_oh_tr,\n",
    "        feature_names=onehot_names,\n",
    "        class_names=[\"edible\", \"poisonous\"],\n",
    "        discretize_continuous=False,\n",
    "        random_state=seed\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f236d-29f8-46d7-a036-3f22769cd1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_proba(X_oh_batch):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_oh_batch : ndarray (n_samples, n_onehot_features)\n",
    "        0/1 one‑hot rows supplied by LIME.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    probs : ndarray (n_samples, 2)\n",
    "        Columns: P(edible) , P(poisonous)\n",
    "    \"\"\"\n",
    "    # --- 1. one‑hot  ➜  original string categories -------------\n",
    "    cat_matrix = ohe.inverse_transform(X_oh_batch)   # shape (n_samples, 117)\n",
    "\n",
    "    # --- 2. string categories  ➜  label‑encoded ints -----------\n",
    "    #     vectorised column‑by‑column\n",
    "    le_matrix = np.empty_like(cat_matrix, dtype=int)\n",
    "    for j, col in enumerate(X_raw.columns):\n",
    "        le_matrix[:, j] = encoders[col].transform(cat_matrix[:, j])\n",
    "\n",
    "    # --- 3. NBC probability for each row -----------------------\n",
    "    prob_e = []\n",
    "    prob_p = []\n",
    "    for row in le_matrix:\n",
    "        # row is a 1‑D int array; wrap in dict {feature: value}\n",
    "        entry = dict(zip(X_raw.columns, row))\n",
    "        # use your NBC's predict_one, which returns (class, prob)\n",
    "        pred_class, pred_prob = nbc.predict_one(entry)\n",
    "\n",
    "        # compute the *unnormalised* probs for each class\n",
    "        unnorm = {}\n",
    "        for cls in nbc.output_classes:\n",
    "            p = nbc.output_class_probs[cls]\n",
    "            for ft, val in entry.items():\n",
    "                p *= nbc.per_class_feature_probs[cls][ft][val]\n",
    "            unnorm[cls] = p\n",
    "        total = unnorm['e'] + unnorm['p']\n",
    "        prob_e.append(unnorm['e'] / total)\n",
    "        prob_p.append(unnorm['p'] / total)\n",
    "\n",
    "    return np.column_stack([prob_e, prob_p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c9bfab-9e77-47b8-9186-6fb7037a38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_freq, agg_wt = Counter(), defaultdict(float)\n",
    "seeds = (0, 1, 2)\n",
    "\n",
    "# (6) Loop seeds & medoids\n",
    "for seed in seeds:\n",
    "    explainer = LimeTabularExplainer(\n",
    "        training_data        = bg_le,\n",
    "        feature_names        = list(X_le_tr.columns),\n",
    "        class_names          = [\"edible\",\"poisonous\"],\n",
    "        categorical_features = cat_feats,\n",
    "        categorical_names    = cat_names,\n",
    "        mode                 = \"classification\",\n",
    "        random_state         = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affcef90-1fe8-4a1d-9149-5daa59580f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " for row in med_le:\n",
    "        exp = explainer.explain_instance(\n",
    "            row, \n",
    "            lambda arr: np.array([nbc.predict_one(pd.Series(x))[1] for x in arr]), \n",
    "            num_features=5\n",
    "        )\n",
    "        for feat, wt in exp.as_list(label=1):\n",
    "            agg_freq[feat] += 1\n",
    "            agg_wt[feat]   += wt\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3fa70-2812-4a81-a05c-df27fe5b3cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5.  SUMMARY CSV\n",
    "# ---------------------------------------------------------------\n",
    "k_total = k * len(seeds)\n",
    "rows = [\n",
    "    {\n",
    "        \"feature\": f,\n",
    "        \"pct_in_top5\": 100 * agg_freq[f] / k_total,\n",
    "        \"mean_signed_weight\": agg_weight[f] / agg_freq[f],\n",
    "    }\n",
    "    for f in agg_freq\n",
    "]\n",
    "summary_df = pd.DataFrame(rows).sort_values(\n",
    "    [\"pct_in_top5\", \"mean_signed_weight\"], ascending=False\n",
    ")\n",
    "\n",
    "summary_df.to_csv(\"eval/lime_results/lime_nbc_summary1.csv\", index=False)\n",
    "print(\"sweet it worked: wrote lime_nbc_summary.csv with\", len(summary_df), \"rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b1c1b-5dbf-42c5-8c2a-45911b3fa4e0",
   "metadata": {},
   "source": [
    "odor_f\t100 %\t+0.106\t“Odor = foul” is in every explanation and increases the NBC’s confidence in the predicted class (almost always poisonous). It’s the model’s strongest universal cue.\n",
    "gill‑color_b\t100 %\t+0.088\tHaving brown gills consistently supports the prediction (likely poisonous).\n",
    "ring‑type_l\t100 %\t+0.053\tLarge ring type also pushes probability toward the predicted class.\n",
    "odor_n\t100 %\t‑0.132\t“Odor = none” appears everywhere but with a negative effect – it pulls the model away from the current prediction. That usually means the model uses odor = none as evidence against poison.\n",
    "ring‑type_p\t98 %\t‑0.050\tPartial ring is almost everywhere and slightly decreases confidence; perhaps NBC associates partial rings with edible mushrooms.\n",
    "spore‑print‑color_h\t1.7 %\t+0.041\t“Spore‑print = chocolate” (value h) barely shows up (only 2 runs out of 120) so it’s not a globally important cue, but when it does appear it nudges the probability up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
