{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5307ddd1-c4a0-4da0-8cf1-6145260b3b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    30] loss: 2.04228\n",
      "example:  predicted tensor([[0.4798, 0.5202],\n",
      "        [0.4821, 0.5179],\n",
      "        [0.4937, 0.5063],\n",
      "        [0.4547, 0.5453],\n",
      "        [0.4481, 0.5519]]) , actual tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]]) \n",
      "\n",
      "------------------------------\n",
      "[2,    30] loss: 1.96896\n",
      "example:  predicted tensor([[0.5452, 0.4548],\n",
      "        [0.4842, 0.5158],\n",
      "        [0.4761, 0.5239],\n",
      "        [0.4833, 0.5167],\n",
      "        [0.5355, 0.4645]]) , actual tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]]) \n",
      "\n",
      "------------------------------\n",
      "[3,    30] loss: 1.88677\n",
      "example:  predicted tensor([[0.4438, 0.5562],\n",
      "        [0.4223, 0.5777],\n",
      "        [0.4437, 0.5563],\n",
      "        [0.5243, 0.4757],\n",
      "        [0.4294, 0.5706]]) , actual tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]]) \n",
      "\n",
      "------------------------------\n",
      "[4,    30] loss: 1.76487\n",
      "example:  predicted tensor([[0.3521, 0.6479],\n",
      "        [0.3953, 0.6047],\n",
      "        [0.3703, 0.6297],\n",
      "        [0.5182, 0.4818],\n",
      "        [0.4070, 0.5930]]) , actual tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]]) \n",
      "\n",
      "------------------------------\n",
      "[5,    30] loss: 1.63522\n",
      "example:  predicted tensor([[0.4077, 0.5923],\n",
      "        [0.3868, 0.6132],\n",
      "        [0.3266, 0.6734],\n",
      "        [0.6444, 0.3556],\n",
      "        [0.4106, 0.5894]]) , actual tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]]) \n",
      "\n",
      "------------------------------\n",
      "sample: tensor([[0.6348, 0.3652],\n",
      "        [0.4158, 0.5842],\n",
      "        [0.3713, 0.6287],\n",
      "        [0.4547, 0.5453],\n",
      "        [0.3695, 0.6305]], grad_fn=<SliceBackward0>) tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "training: 0.9262754753111749\n",
      "sample: tensor([[0.4540, 0.5460],\n",
      "        [0.4463, 0.5537],\n",
      "        [0.4275, 0.5725],\n",
      "        [0.3596, 0.6404],\n",
      "        [0.3908, 0.6092]], grad_fn=<SliceBackward0>) tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "test: 0.929889298892989\n",
      "sample: tensor([[0.4687, 0.5313],\n",
      "        [0.4213, 0.5787],\n",
      "        [0.3896, 0.6104],\n",
      "        [0.4259, 0.5741],\n",
      "        [0.3736, 0.6264]], grad_fn=<SliceBackward0>) tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "prob: 0.9266371245691778\n",
      "sample: tensor([[0.4687, 0.5313],\n",
      "        [0.4213, 0.5787],\n",
      "        [0.3896, 0.6104],\n",
      "        [0.4259, 0.5741],\n",
      "        [0.3736, 0.6264]], grad_fn=<SliceBackward0>) tensor([[1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "test: 0.9266371245691778\n"
     ]
    }
   ],
   "source": [
    "%run models/neural_nets.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cadbad0-5b17-42fd-8362-827b527b13ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One‑hot shape: (8124, 117)\n",
      "Features: 117\n",
      "Train/test sizes: 5686 2438\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1) Load data\n",
    "df = pd.read_csv(\"data/mushroom_dataset.csv\")\n",
    "\n",
    "# 2) Extract raw X and y\n",
    "X_raw = df.drop(columns=\"class\")\n",
    "y_raw = df[\"class\"]\n",
    "\n",
    "# 3) Label‑encode the target\n",
    "le = LabelEncoder().fit(y_raw)\n",
    "y = le.transform(y_raw)    # 0='e', 1='p'\n",
    "\n",
    "# 4) One‑hot encode all features\n",
    "X_oh_df = pd.get_dummies(X_raw, drop_first=False)\n",
    "feature_names_oh = X_oh_df.columns.tolist()\n",
    "X_oh = X_oh_df.values      # convert to numpy\n",
    "\n",
    "# 5) Stratified train/test split\n",
    "X_train_oh, X_test_oh, y_train, y_test = train_test_split(\n",
    "    X_oh, y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"One‑hot shape:\", X_oh.shape)\n",
    "print(\"Features:\", len(feature_names_oh))\n",
    "print(\"Train/test sizes:\", X_train_oh.shape[0], X_test_oh.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d37eed-2bf5-4ee2-9fe3-3ce59a4c74b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 40 medoids from test set\n",
      "Example medoid indices: [ 736  589 2233 1180    3 1549 1930 1764 2187  514]\n",
      "Medoids shape: (40, 117)\n"
     ]
    }
   ],
   "source": [
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "# 6) Find 40 medoids on the ONE‑HOT test set\n",
    "kmed = KMedoids(n_clusters=40, metric=\"manhattan\", random_state=0)\n",
    "kmed.fit(X_test_oh)\n",
    "\n",
    "# medoid indices into X_test_oh\n",
    "med_idx    = kmed.medoid_indices_\n",
    "# the actual medoid rows (one‑hot)\n",
    "medoids_oh = X_test_oh[med_idx]\n",
    "\n",
    "print(f\"Selected {len(med_idx)} medoids from test set\")\n",
    "print(\"Example medoid indices:\", med_idx[:10])\n",
    "print(\"Medoids shape:\", medoids_oh.shape)  # should be (40, n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb99cd10-923a-4c45-bd74-2d1203ee973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_proba_oh(arr_oh):\n",
    "    \"\"\"\n",
    "    Input:  (n_samples × d) one‑hot numpy array\n",
    "    Output: (n_samples × 2) probability array [[p(edible), p(poisonous)], …]\n",
    "    \"\"\"\n",
    "    arr = np.atleast_2d(arr_oh).astype(np.float32)\n",
    "    with torch.no_grad():\n",
    "        logits = model(torch.from_numpy(arr).int())  # your PyTorch model\n",
    "        probs  = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbcd165d-9a8c-4066-89e0-b050cf8d0636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data         = X_train_oh,\n",
    "    feature_names         = feature_names_oh,\n",
    "    class_names           = [\"edible\",\"poisonous\"],\n",
    "    categorical_features  = list(range(X_train_oh.shape[1])),\n",
    "    discretize_continuous = False,\n",
    "    random_state          = 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93159efc-81ba-4795-b49d-12aa5e4e3a5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m pred_cls = np.argmax(nn_proba_oh(row))\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# get a full list of coefficients (one for every dummy)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m exp = \u001b[43mexplainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnn_proba_oh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train_oh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m raw = exp.as_list(label=pred_cls)\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# now filter only those dummies where row[idx]==1, keep top 5\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Receipts\\Purdue 2024-2026\\CS573\\NN branch\\CS573MushroomProject\\.venv\\Lib\\site-packages\\lime\\lime_tabular.py:355\u001b[39m, in \u001b[36mLimeTabularExplainer.explain_instance\u001b[39m\u001b[34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[39m\n\u001b[32m    348\u001b[39m     scaled_data = (data - \u001b[38;5;28mself\u001b[39m.scaler.mean_) / \u001b[38;5;28mself\u001b[39m.scaler.scale_\n\u001b[32m    349\u001b[39m distances = sklearn.metrics.pairwise_distances(\n\u001b[32m    350\u001b[39m         scaled_data,\n\u001b[32m    351\u001b[39m         scaled_data[\u001b[32m0\u001b[39m].reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m),\n\u001b[32m    352\u001b[39m         metric=distance_metric\n\u001b[32m    353\u001b[39m ).ravel()\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m yss = \u001b[43mpredict_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[38;5;66;03m# for classification, the model needs to provide a list of tuples - classes\u001b[39;00m\n\u001b[32m    358\u001b[39m \u001b[38;5;66;03m# along with prediction probabilities\u001b[39;00m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mclassification\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mnn_proba_oh\u001b[39m\u001b[34m(arr_oh)\u001b[39m\n\u001b[32m      6\u001b[39m arr = np.atleast_2d(arr_oh).astype(np.float32)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# your PyTorch model\u001b[39;00m\n\u001b[32m      9\u001b[39m     probs  = torch.softmax(logits, dim=\u001b[32m1\u001b[39m).cpu().numpy()\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m probs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Receipts\\Purdue 2024-2026\\CS573\\NN branch\\CS573MushroomProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Receipts\\Purdue 2024-2026\\CS573\\NN branch\\CS573MushroomProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Receipts\\Purdue 2024-2026\\CS573\\NN branch\\CS573MushroomProject\\models\\neural_nets.py:70\u001b[39m, in \u001b[36mneural_network.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     68\u001b[39m embed_inputs = []\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feature_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(features)):\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     embed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeature_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     embed_inputs.append(embed)\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m#print(embed.shape)\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m#print(x[:5], torch.cat(embed_inputs, dim = 1)[:5,:10])\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Receipts\\Purdue 2024-2026\\CS573\\NN branch\\CS573MushroomProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Receipts\\Purdue 2024-2026\\CS573\\NN branch\\CS573MushroomProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Receipts\\Purdue 2024-2026\\CS573\\NN branch\\CS573MushroomProject\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001b[39m, in \u001b[36mEmbedding.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\Receipts\\Purdue 2024-2026\\CS573\\NN branch\\CS573MushroomProject\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:2551\u001b[39m, in \u001b[36membedding\u001b[39m\u001b[34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[39m\n\u001b[32m   2545\u001b[39m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[32m   2546\u001b[39m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[32m   2547\u001b[39m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   2548\u001b[39m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[32m   2549\u001b[39m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[32m   2550\u001b[39m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[32m-> \u001b[39m\u001b[32m2551\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIndexError\u001b[39m: index out of range in self"
     ]
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import numpy as np\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# 5) Run LIME on each medoid × 3 seeds, filter out dummy=0  \n",
    "agg_freq, agg_wt = Counter(), defaultdict(float)\n",
    "seeds = [0,1,2]\n",
    "\n",
    "for seed in seeds:\n",
    "    # ← make a brand‐new explainer each time, with its own random_state\n",
    "    explainer = LimeTabularExplainer(\n",
    "        training_data         = X_train_oh,\n",
    "        feature_names         = feature_names_oh,\n",
    "        class_names           = [\"edible\",\"poisonous\"],\n",
    "        categorical_features  = list(range(X_train_oh.shape[1])),\n",
    "        discretize_continuous = False,\n",
    "        random_state          = seed\n",
    "    )\n",
    "\n",
    "    for row in medoids_oh:\n",
    "        # predict class for this medoid\n",
    "        pred_cls = np.argmax(nn_proba_oh(row))\n",
    "\n",
    "        # get a full list of coefficients (one for every dummy)\n",
    "        exp = explainer.explain_instance(\n",
    "            row,\n",
    "            nn_proba_oh,\n",
    "            num_features=X_train_oh.shape[1]\n",
    "        )\n",
    "        raw = exp.as_list(label=pred_cls)\n",
    "\n",
    "        # now filter only those dummies where row[idx]==1, keep top 5\n",
    "        count = 0\n",
    "        for feat_val, wt in raw:\n",
    "            feat = feat_val.split(\"=\",1)[0]\n",
    "            idx  = feature_names_oh.index(feat)\n",
    "            if row[idx] == 1:\n",
    "                agg_freq[feat] += 1\n",
    "                agg_wt[feat]   += wt\n",
    "                count += 1\n",
    "                if count == 5:\n",
    "                    break\n",
    "\n",
    "# …then build your summary_df exactly as before…\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799234c-c8db-4a8d-9307-0619a56e8976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
